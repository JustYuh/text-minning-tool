# Examples for the Text Mining Tool

This directory contains example scripts that demonstrate how to use the Text Mining Tool.

## Basic Usage Example

The `basic_usage.py` script demonstrates how to use the tool with minimal dependencies (NLTK only):

```bash
python examples/basic_usage.py
```

This script shows how to:
- Create a text processor
- Process text
- Extract tokens and sentences
- Save the results to a file

## Advanced Usage Example

The `advanced_usage.py` script demonstrates how to use the tool with additional dependencies:

```bash
python examples/advanced_usage.py
```

This script shows how to:
- Perform sentiment analysis
- Extract named entities
- Extract keywords
- Perform topic modeling
- Generate visualizations

Note: This example requires additional dependencies to be installed:
- spaCy: `pip install spacy`
- transformers: `pip install transformers`
- gensim: `pip install gensim`
- scikit-learn: `pip install scikit-learn`
- matplotlib: `pip install matplotlib`

## NLTK Mining Example

The `nltk_mining.py` script is a standalone script for text mining using NLTK:

```bash
python examples/nltk_mining.py
```

This script shows how to:
- Preprocess text using NLTK
- Tokenize text
- Remove stopwords
- Perform stemming and lemmatization
- Analyze word frequencies
- Generate visualizations

## Sample Results

The `sample_results` directory contains example output files generated by the tool:
- `results.json`: Full results in JSON format
- `preprocessed_docs.json`: Preprocessed documents in JSON format
- `preprocessed_docs.csv`: Preprocessed documents in CSV format

# Quick Start Guide

## Basic Usage Examples

### 1. Web Interface

1. Start the server:
```bash
python src/web/app.py
```

2. Open http://localhost:5000 in your browser

3. Example text to try:
```
The new iPhone 14 Pro Max is an excellent device. The camera quality is outstanding, 
and the battery life is impressive. However, the price is quite high. Apple has 
done a great job with the design, but Samsung's latest models offer good competition.
```

This will demonstrate:
- Sentiment analysis (mixed sentiment)
- Named entities (iPhone, Apple, Samsung)
- Keywords (camera, battery, price)
- Visualizations

### 2. Python API Usage

```python
import requests

# Basic text processing
def process_text(text):
    response = requests.post(
        'http://localhost:5000/api/process',
        json={'text': text}
    )
    return response.json()

# Sentiment analysis only
def analyze_sentiment(text):
    response = requests.post(
        'http://localhost:5000/api/analyze',
        json={
            'text': text,
            'analysis_type': 'sentiment'
        }
    )
    return response.json()

# Example usage
text = "This product is amazing! The quality is excellent."
results = process_text(text)
print("Full Analysis:", results)

sentiment = analyze_sentiment(text)
print("Sentiment:", sentiment)
```

### 3. Batch Processing

```python
import json
from pathlib import Path

def process_files(input_dir, output_dir):
    input_path = Path(input_dir)
    output_path = Path(output_dir)
    output_path.mkdir(exist_ok=True)
    
    for file in input_path.glob('*.txt'):
        # Read input file
        text = file.read_text(encoding='utf-8')
        
        # Process text
        response = requests.post(
            'http://localhost:5000/api/process',
            json={'text': text}
        )
        results = response.json()
        
        # Save results
        output_file = output_path / f"{file.stem}_results.json"
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2)

# Example usage
process_files('data/input', 'data/output')
```

### 4. Visualization API

```python
def generate_wordcloud(text):
    response = requests.post(
        'http://localhost:5000/api/visualize',
        json={
            'text': text,
            'visualization_type': 'wordcloud'
        }
    )
    return response.json()

# Example usage
text = """
Machine learning is a field of artificial intelligence that uses statistical 
techniques to give computer systems the ability to learn from data, without 
being explicitly programmed. The process of machine learning is similar to 
that of data mining.
"""

visualization = generate_wordcloud(text)
print("Wordcloud URL:", visualization['visualization_url'])
```

## Common Operations

### Text Preprocessing
```python
from src.preprocessing.text_processor import TextProcessor

processor = TextProcessor()
text = "This is a sample text! It contains multiple sentences..."
result = processor.process(text)

print("Tokens:", result['tokens'])
print("Sentences:", result['sentences'])
```

### Sentiment Analysis
```python
from src.analysis.sentiment import SentimentAnalyzer

analyzer = SentimentAnalyzer()
text = "I love this product! It's amazing and works perfectly."
sentiment = analyzer.analyze(text)

print("Sentiment:", sentiment['label'])
print("Score:", sentiment['score'])
```

### Named Entity Recognition
```python
from src.analysis.entities import NamedEntityRecognizer

ner = NamedEntityRecognizer()
text = "Microsoft CEO Satya Nadella announced new AI features in Windows."
entities = ner.extract_entities(text)

for entity in entities:
    print(f"{entity['text']} ({entity['type']})")
```

### Keyword Extraction
```python
from src.analysis.keywords import KeywordExtractor

extractor = KeywordExtractor()
text = "Python is a versatile programming language used in data science."
keywords = extractor.extract_keywords(text)

for keyword in keywords:
    print(f"{keyword['text']}: {keyword['score']}")
```

## Tips and Best Practices

1. **Input Text**
   - Clean special characters if needed
   - Use UTF-8 encoding for files
   - Split long texts into manageable chunks

2. **Performance**
   - Use batch processing for multiple files
   - Cache results when processing same text multiple times
   - Consider using the async API for large-scale processing

3. **Visualization**
   - Save generated visualizations with unique names
   - Use appropriate chart types for different analyses
   - Customize visualization parameters as needed

4. **Error Handling**
   - Always check API response status
   - Handle timeouts and connection errors
   - Validate input text before processing 